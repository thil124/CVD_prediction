import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import recall_score, accuracy_score, roc_auc_score, confusion_matrix, classification_report, precision_score
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from collections import Counter

# Settings
plt.rcParams['font.sans-serif'] = ['SimHei']
sns.set_style("whitegrid")

print("Starting improved KNN model training with threshold optimization...")

# Load data
data = pd.read_csv('CVD_cleaned.csv').drop('Checkup', axis=1)
print(f"Data shape: {data.shape}")

# Preprocessing function
def preprocess_data(df):
    df_processed = df.copy()
    
    # Remove duplicates
    df_processed = df_processed.drop_duplicates()
    
    # Binary variable processing
    binary_cols = ['Exercise', 'Heart_Disease', 'Skin_Cancer', 'Other_Cancer',
                   'Depression', 'Diabetes', 'Arthritis', 'Smoking_History']
    for col in binary_cols:
        df_processed[col] = df_processed[col].apply(
            lambda x: 1 if 'Yes' in str(x) else (0 if 'No' in str(x) else x)
        ).astype(int)
    
    # Label encoding for categorical variables
    categorical_cols = ['General_Health', 'Age_Category', 'Sex']
    for col in categorical_cols:
        le = LabelEncoder()
        df_processed[col] = le.fit_transform(df_processed[col].astype(str))
    
    # Standardize numerical variables
    numeric_cols = ['Height_(cm)', 'Weight_(kg)', 'BMI', 'Alcohol_Consumption',
                    'Fruit_Consumption', 'Green_Vegetables_Consumption', 'FriedPotato_Consumption']
    scaler = StandardScaler()
    df_processed[numeric_cols] = scaler.fit_transform(df_processed[numeric_cols])
    
    return df_processed, scaler

# Apply preprocessing
data_processed, scaler = preprocess_data(data)
X = data_processed.drop('Heart_Disease', axis=1)
y = data_processed['Heart_Disease']

print(f"Target variable distribution: {Counter(y)}")
print(f"Heart disease proportion: {y.mean():.3f}")

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTraining set distribution: {Counter(y_train)}")
print(f"Test set distribution: {Counter(y_test)}")

# Apply SMOTE for class imbalance
print("\nApplying SMOTE for class imbalance handling...")
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
print(f"Training set distribution after SMOTE: {Counter(y_train_smote)}")

# Test different K values focusing on recall
print("\nTesting different K values for recall optimization...")

best_recall = 0
best_k = 3
best_model = None

for k in [3, 5, 7, 9, 11, 15, 20]:
    knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='euclidean')
    knn.fit(X_train_smote, y_train_smote)
    
    y_pred = knn.predict(X_test)
    recall = recall_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"K={k}: Recall={recall:.4f}, Accuracy={accuracy:.4f}")
    
    if recall > best_recall:
        best_recall = recall
        best_k = k
        best_model = knn

print(f"\nBest K value: {best_k}")
print(f"Best recall: {best_recall:.4f}")

# -----------------------------
# Threshold optimization
# -----------------------------
y_proba = best_model.predict_proba(X_test)[:, 1]
thresholds = np.arange(0.3, 0.9, 0.01)
best_precision = 0
best_threshold = 0.5
target_recall = best_recall * 0.95  # 保持召回率至少95%原始值

precision_list = []
recall_list = []

for t in thresholds:
    y_pred_thresh = (y_proba >= t).astype(int)
    recall = recall_score(y_test, y_pred_thresh)
    precision = precision_score(y_test, y_pred_thresh, zero_division=0)
    precision_list.append(precision)
    recall_list.append(recall)
    
    if recall >= target_recall and precision > best_precision:
        best_precision = precision
        best_threshold = t

print(f"\nOptimal threshold to maintain recall while improving precision: {best_threshold:.2f}")
print(f"Precision at this threshold: {best_precision:.4f}")

# Final prediction with optimized threshold
y_pred_final = (y_proba >= best_threshold).astype(int)

final_recall = recall_score(y_test, y_pred_final)
final_precision = precision_score(y_test, y_pred_final)
final_accuracy = accuracy_score(y_test, y_pred_final)
final_auc = roc_auc_score(y_test, y_proba)

print(f"\n=== Final Model Performance (Threshold={best_threshold:.2f}) ===")
print(f"Precision: {final_precision:.4f}")
print(f"Recall: {final_recall:.4f}")
print(f"Accuracy: {final_accuracy:.4f}")
print(f"AUC: {final_auc:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred_final))

# Confusion matrix
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred_final)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Heart Disease', 'Heart Disease'],
            yticklabels=['No Heart Disease', 'Heart Disease'])
plt.title(f'KNN Confusion Matrix (K={best_k}, Threshold={best_threshold:.2f})\nRecall: {final_recall:.4f}')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()

# Threshold vs Precision/Recall curve
plt.figure(figsize=(10, 6))
plt.plot(thresholds, precision_list, label='Precision', color='blue', linewidth=2)
plt.plot(thresholds, recall_list, label='Recall', color='red', linewidth=2)
plt.axvline(best_threshold, color='green', linestyle='--', label=f'Optimal Threshold ({best_threshold:.2f})')
plt.xlabel("Threshold")
plt.ylabel("Score")
plt.title("Precision and Recall vs Threshold")
plt.legend()
plt.grid(True)
plt.show()

# Save model and scaler
joblib.dump(best_model, 'improved_knn_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
print("\nModel and scaler saved successfully.")
