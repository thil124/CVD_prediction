import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import recall_score, precision_score, accuracy_score, roc_auc_score, classification_report, confusion_matrix, f1_score
from imblearn.over_sampling import SMOTE
from sklearn.calibration import CalibratedClassifierCV
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from collections import Counter

# Settings
plt.rcParams['font.sans-serif'] = ['SimHei']
sns.set_style("whitegrid")

print("Starting Enhanced KNN Optimization...")

# ===========================
# Load and preprocess data
# ===========================
data = pd.read_csv('CVD_cleaned.csv').drop('Checkup', axis=1)
print(f"Data shape: {data.shape}")

def preprocess_data(df):
    df_processed = df.copy()
    binary_cols = ['Exercise', 'Heart_Disease', 'Skin_Cancer', 'Other_Cancer',
                   'Depression', 'Diabetes', 'Arthritis', 'Smoking_History']
    for col in binary_cols:
        df_processed[col] = df_processed[col].apply(lambda x: 1 if 'Yes' in str(x) else (0 if 'No' in str(x) else x)).astype(int)
    categorical_cols = ['General_Health', 'Age_Category', 'Sex']
    for col in categorical_cols:
        le = LabelEncoder()
        df_processed[col] = le.fit_transform(df_processed[col].astype(str))
    numeric_cols = ['Height_(cm)', 'Weight_(kg)', 'BMI', 'Alcohol_Consumption',
                    'Fruit_Consumption', 'Green_Vegetables_Consumption', 'FriedPotato_Consumption']
    scaler = StandardScaler()
    df_processed[numeric_cols] = scaler.fit_transform(df_processed[numeric_cols])
    return df_processed, scaler

data_processed, scaler = preprocess_data(data)
X = data_processed.drop('Heart_Disease', axis=1)
y = data_processed['Heart_Disease']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Apply SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

print(f"Training set after SMOTE: {Counter(y_train_smote)}")

# ===========================
# Scan K values and train KNN
# ===========================
best_recall = 0
best_k = 3
best_model = None

for k in [3,5,7,9,11,15,20]:
    knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='euclidean')
    knn.fit(X_train_smote, y_train_smote)
    y_pred = knn.predict(X_test)
    recall = recall_score(y_test, y_pred)
    if recall > best_recall:
        best_recall = recall
        best_k = k
        best_model = knn

print(f"\nBest K={best_k}, Best Recall={best_recall:.4f}")

# ===========================
# Probability calibration
# ===========================
calibrated_knn = CalibratedClassifierCV(best_model, cv=3)
calibrated_knn.fit(X_train_smote, y_train_smote)


# ===========================
# Threshold optimization
# ===========================
y_proba = calibrated_knn.predict_proba(X_test)[:,1]
thresholds = np.arange(0.1, 0.9, 0.01)
target_recall = best_recall * 0.95

best_precision = 0
best_threshold = 0.5
best_f1 = 0

precision_list = []
recall_list = []
f1_list = []

for t in thresholds:
    y_pred = (y_proba >= t).astype(int)
    recall = recall_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    
    precision_list.append(precision)
    recall_list.append(recall)
    f1_list.append(f1)
    
    if recall >= target_recall:
        if f1 > best_f1:
            best_f1 = f1
            best_threshold = t
            best_precision = precision

print(f"\nOptimal Threshold: {best_threshold:.2f}")
print(f"Precision: {best_precision:.4f}")
print(f"Recall: {recall_score(y_test,(y_proba>=best_threshold).astype(int)):.4f}")
print(f"F1-score: {best_f1:.4f}")

# ===========================
# Final evaluation
# ===========================
y_pred_final = (y_proba >= best_threshold).astype(int)
print("\n=== Final Model Performance ===")
print(classification_report(y_test, y_pred_final, digits=4))
print(f"AUC: {roc_auc_score(y_test, y_proba):.4f}")
